# Вычисление академической тошноты текста

#### Запуск 
```
python main.py [-h] -dir <dir_name> [-n <N_workers>] [-db <db_name>]
```
по умолчаниию: ```n = 1, db = "Density.db"```

используемая версия Python: 3.5.2

#### Комментарии по решению
* Все сообщения логгируются в файле ```adparser.log```
* Обработка файлов запускается в n потоков одновременно, список подается в очередь ```Queue```
	* Чтобы понять, что все файлы обработаны, в конец очереди записывается терминирующий символ для всех потоков
	* Результат для каждого файла записывается в другую очередь, из которой уже идет запись в SQLite
	* Запись в базу производится одним потоком, параллельно с обработкой файлов. В процессе решения выяснилось, что SQLite и многопоточная запись в базу не совместимы. Поэтому, чтобы как-то распараллелить этот процесс, и было введено 2 очереди сообщений.
* Вычисление академической тошноты производится в классе ```AdParser```
	* Токенизируется с помощью регулярных выражений
		* Искал все слова в тексте, включая обозначения и названия моделей. Насколько я понял, их тоже стоит учитывать.
		* Таким образом, у некоторых текстов из выборки (например 269 или 849) тошнота получилось достаточно большой, т.к. названия или обозначения занимают большую часть текста
		* Если это предположение неверно, могу поправить.
	* Используется альтернативный список стоп-слов из файла ```sw.txt```
	* Стемминг делался с помощью библиотеки NLTK
* Критерий определения мошенничества прокомментирован в коде метода ```AdParser.parse```